---
sidebar_position: 3
---

# S3 Media Storage

Amazon S3 provides the primary media storage layer for QuikApp, handling photos, videos, voice notes, and file attachments with automatic lifecycle management.

## Storage Architecture

```
┌─────────────────────────────────────────────────────────────────────────────────────┐
│                              S3 Media Storage Architecture                           │
├─────────────────────────────────────────────────────────────────────────────────────┤
│                                                                                      │
│  ┌────────────────────────────────────────────────────────────────────────────────┐ │
│  │                              Upload Flow                                        │ │
│  │                                                                                 │ │
│  │  Client App                                                                     │ │
│  │      │                                                                          │ │
│  │      │  1. Request pre-signed URL                                               │ │
│  │      ▼                                                                          │ │
│  │  Media Service ──────────────────────────────────────────────────────────────┐  │ │
│  │      │                                                                       │  │ │
│  │      │  2. Generate pre-signed PUT URL                                       │  │ │
│  │      │     (expires in 15 minutes)                                           │  │ │
│  │      ▼                                                                       │  │ │
│  │  Client App                                                                  │  │ │
│  │      │                                                                       │  │ │
│  │      │  3. Upload encrypted media directly to S3                            │  │ │
│  │      │     (client-side E2EE + server-side SSE-KMS)                         │  │ │
│  │      ▼                                                                       │  │ │
│  │  ┌─────────────────────────────────────────────────────────────────────┐    │  │ │
│  │  │                         S3 Bucket                                    │    │  │ │
│  │  │                                                                      │    │  │ │
│  │  │  ┌──────────┐  ┌──────────┐  ┌──────────┐  ┌──────────┐            │    │  │ │
│  │  │  │ /photos/ │  │ /videos/ │  │ /voice/  │  │ /files/  │            │    │  │ │
│  │  │  │          │  │          │  │          │  │          │            │    │  │ │
│  │  │  │ .jpg     │  │ .mp4     │  │ .opus    │  │ .pdf     │            │    │  │ │
│  │  │  │ .png     │  │ .webm    │  │ .aac     │  │ .docx    │            │    │  │ │
│  │  │  │ .webp    │  │ .mov     │  │ .m4a     │  │ .xlsx    │            │    │  │ │
│  │  │  │ .heic    │  │ .avi     │  │          │  │ .zip     │            │    │  │ │
│  │  │  └──────────┘  └──────────┘  └──────────┘  └──────────┘            │    │  │ │
│  │  │                                                                      │    │  │ │
│  │  └─────────────────────────────────────────────────────────────────────┘    │  │ │
│  │      │                                                                       │  │ │
│  │      │  4. S3 Event Notification                                            │  │ │
│  │      ▼                                                                       │  │ │
│  │  Lambda (Thumbnail Generator)                                                │  │ │
│  │      │                                                                       │  │ │
│  │      │  5. Generate thumbnails/previews                                     │  │ │
│  │      ▼                                                                       │  │ │
│  │  S3 Thumbnails Bucket ◄──────────────────────────────────────────────────────┘  │ │
│  │                                                                                 │ │
│  └────────────────────────────────────────────────────────────────────────────────┘ │
│                                                                                      │
└─────────────────────────────────────────────────────────────────────────────────────┘
```

## Bucket Structure

### Production Buckets

| Bucket | Purpose | Region | Replication |
|--------|---------|--------|-------------|
| `quikapp-media-prod` | Primary media storage | us-east-1 | Multi-region |
| `quikapp-media-prod-eu` | EU replica | eu-west-1 | Passive |
| `quikapp-media-prod-apac` | APAC replica | ap-southeast-1 | Passive |
| `quikapp-thumbnails-prod` | Generated previews | us-east-1 | Multi-region |
| `quikapp-archives-prod` | Long-term storage | us-east-1 | None |
| `quikapp-exports-prod` | User data exports | us-east-1 | None |
| `quikapp-logs-prod` | Access/audit logs | us-east-1 | None |

### Object Key Structure

```
quikapp-media-{env}/
├── {workspace_id}/
│   ├── photos/
│   │   └── {channel_id}/
│   │       └── {message_id}/
│   │           └── {uuid}.{ext}.enc
│   ├── videos/
│   │   └── {channel_id}/
│   │       └── {message_id}/
│   │           └── {uuid}.{ext}.enc
│   ├── voice/
│   │   └── {channel_id}/
│   │       └── {message_id}/
│   │           └── {uuid}.opus.enc
│   ├── files/
│   │   └── {channel_id}/
│   │       └── {message_id}/
│   │           └── {uuid}_{filename}.enc
│   └── avatars/
│       └── {user_id}/
│           └── {uuid}.webp
└── dm/
    └── {conversation_id}/
        └── ...same structure...
```

---

## Terraform Configuration

### Main Bucket Configuration

```hcl
# terraform/modules/s3/main.tf

resource "aws_s3_bucket" "media" {
  bucket = "quikapp-media-${var.environment}"

  tags = {
    Name        = "QuikApp Media Storage"
    Environment = var.environment
    Service     = "media"
  }
}

# Enable versioning for production
resource "aws_s3_bucket_versioning" "media" {
  bucket = aws_s3_bucket.media.id
  versioning_configuration {
    status = var.environment == "prod" ? "Enabled" : "Disabled"
  }
}

# Server-side encryption with KMS
resource "aws_s3_bucket_server_side_encryption_configuration" "media" {
  bucket = aws_s3_bucket.media.id

  rule {
    apply_server_side_encryption_by_default {
      sse_algorithm     = "aws:kms"
      kms_master_key_id = aws_kms_key.media_key.arn
    }
    bucket_key_enabled = true
  }
}

# Block all public access
resource "aws_s3_bucket_public_access_block" "media" {
  bucket = aws_s3_bucket.media.id

  block_public_acls       = true
  block_public_policy     = true
  ignore_public_acls      = true
  restrict_public_buckets = true
}

# CORS configuration for client uploads
resource "aws_s3_bucket_cors_configuration" "media" {
  bucket = aws_s3_bucket.media.id

  cors_rule {
    allowed_headers = ["*"]
    allowed_methods = ["GET", "PUT", "POST", "HEAD"]
    allowed_origins = var.allowed_origins
    expose_headers  = ["ETag", "x-amz-meta-*"]
    max_age_seconds = 3600
  }
}
```

### Lifecycle Rules

```hcl
# terraform/modules/s3/lifecycle.tf

resource "aws_s3_bucket_lifecycle_configuration" "media" {
  bucket = aws_s3_bucket.media.id

  # Photos - transition to IA after 30 days, Glacier after 90 days
  rule {
    id     = "photos-lifecycle"
    status = "Enabled"

    filter {
      prefix = "photos/"
    }

    transition {
      days          = 30
      storage_class = "STANDARD_IA"
    }

    transition {
      days          = 90
      storage_class = "GLACIER"
    }

    expiration {
      days = 365
    }

    noncurrent_version_expiration {
      noncurrent_days = 30
    }
  }

  # Videos - more aggressive archival (larger files)
  rule {
    id     = "videos-lifecycle"
    status = "Enabled"

    filter {
      prefix = "videos/"
    }

    transition {
      days          = 7
      storage_class = "STANDARD_IA"
    }

    transition {
      days          = 30
      storage_class = "GLACIER"
    }

    expiration {
      days = 180
    }
  }

  # Voice notes - short retention
  rule {
    id     = "voice-lifecycle"
    status = "Enabled"

    filter {
      prefix = "voice/"
    }

    transition {
      days          = 7
      storage_class = "STANDARD_IA"
    }

    expiration {
      days = 30
    }
  }

  # Temporary uploads - auto-delete incomplete
  rule {
    id     = "abort-incomplete-uploads"
    status = "Enabled"

    abort_incomplete_multipart_upload {
      days_after_initiation = 1
    }
  }
}

# Thumbnails bucket - shorter lifecycle
resource "aws_s3_bucket_lifecycle_configuration" "thumbnails" {
  bucket = aws_s3_bucket.thumbnails.id

  rule {
    id     = "thumbnails-expiration"
    status = "Enabled"

    expiration {
      days = 7
    }
  }
}
```

### Cross-Region Replication

```hcl
# terraform/modules/s3/replication.tf

resource "aws_s3_bucket_replication_configuration" "media" {
  count = var.environment == "prod" ? 1 : 0

  bucket = aws_s3_bucket.media.id
  role   = aws_iam_role.replication.arn

  rule {
    id     = "replicate-to-eu"
    status = "Enabled"

    filter {
      prefix = ""
    }

    destination {
      bucket        = aws_s3_bucket.media_eu.arn
      storage_class = "STANDARD_IA"

      encryption_configuration {
        replica_kms_key_id = aws_kms_key.media_key_eu.arn
      }
    }

    source_selection_criteria {
      sse_kms_encrypted_objects {
        status = "Enabled"
      }
    }

    delete_marker_replication {
      status = "Enabled"
    }
  }

  rule {
    id     = "replicate-to-apac"
    status = "Enabled"

    filter {
      prefix = ""
    }

    destination {
      bucket        = aws_s3_bucket.media_apac.arn
      storage_class = "STANDARD_IA"

      encryption_configuration {
        replica_kms_key_id = aws_kms_key.media_key_apac.arn
      }
    }

    source_selection_criteria {
      sse_kms_encrypted_objects {
        status = "Enabled"
      }
    }
  }
}
```

---

## Pre-Signed URLs

### URL Generation (Go Service)

```go
// services/media-service/internal/s3/presigned.go

package s3

import (
    "context"
    "fmt"
    "time"

    "github.com/aws/aws-sdk-go-v2/aws"
    "github.com/aws/aws-sdk-go-v2/service/s3"
    "github.com/google/uuid"
)

type PresignedURLService struct {
    client       *s3.Client
    presignClient *s3.PresignClient
    bucket       string
    cdnDomain    string
}

type UploadURLRequest struct {
    WorkspaceID string
    ChannelID   string
    MessageID   string
    MediaType   string // photos, videos, voice, files
    Filename    string
    ContentType string
    FileSize    int64
}

type UploadURLResponse struct {
    UploadURL   string            `json:"upload_url"`
    ObjectKey   string            `json:"object_key"`
    ExpiresAt   time.Time         `json:"expires_at"`
    Headers     map[string]string `json:"headers"`
}

func (s *PresignedURLService) GenerateUploadURL(
    ctx context.Context,
    req UploadURLRequest,
) (*UploadURLResponse, error) {
    // Generate unique object key
    objectKey := fmt.Sprintf(
        "%s/%s/%s/%s/%s_%s.enc",
        req.WorkspaceID,
        req.MediaType,
        req.ChannelID,
        req.MessageID,
        uuid.New().String(),
        sanitizeFilename(req.Filename),
    )

    // Pre-signed PUT URL (15 minute expiration)
    presignReq, err := s.presignClient.PresignPutObject(ctx, &s3.PutObjectInput{
        Bucket:             aws.String(s.bucket),
        Key:                aws.String(objectKey),
        ContentType:        aws.String(req.ContentType),
        ContentLength:      aws.Int64(req.FileSize),
        ServerSideEncryption: "aws:kms",
        Metadata: map[string]string{
            "workspace-id": req.WorkspaceID,
            "channel-id":   req.ChannelID,
            "message-id":   req.MessageID,
            "original-name": req.Filename,
        },
    }, func(opts *s3.PresignOptions) {
        opts.Expires = 15 * time.Minute
    })
    if err != nil {
        return nil, fmt.Errorf("failed to generate presigned URL: %w", err)
    }

    return &UploadURLResponse{
        UploadURL: presignReq.URL,
        ObjectKey: objectKey,
        ExpiresAt: time.Now().Add(15 * time.Minute),
        Headers: map[string]string{
            "Content-Type":              req.ContentType,
            "x-amz-server-side-encryption": "aws:kms",
        },
    }, nil
}

func (s *PresignedURLService) GenerateDownloadURL(
    ctx context.Context,
    objectKey string,
    expiration time.Duration,
) (string, error) {
    // For production, return CloudFront signed URL
    if s.cdnDomain != "" {
        return s.generateCloudFrontSignedURL(objectKey, expiration)
    }

    // For dev/staging, return S3 presigned URL
    presignReq, err := s.presignClient.PresignGetObject(ctx, &s3.GetObjectInput{
        Bucket: aws.String(s.bucket),
        Key:    aws.String(objectKey),
    }, func(opts *s3.PresignOptions) {
        opts.Expires = expiration
    })
    if err != nil {
        return "", fmt.Errorf("failed to generate download URL: %w", err)
    }

    return presignReq.URL, nil
}

// Temporary URL that auto-expires (WhatsApp-style "view once")
func (s *PresignedURLService) GenerateViewOnceURL(
    ctx context.Context,
    objectKey string,
) (string, error) {
    // Very short expiration for view-once media
    return s.GenerateDownloadURL(ctx, objectKey, 5*time.Minute)
}
```

### Client Upload (TypeScript)

```typescript
// clients/web/src/services/media-upload.ts

interface UploadProgress {
  loaded: number;
  total: number;
  percentage: number;
}

interface MediaUploadOptions {
  file: File;
  workspaceId: string;
  channelId: string;
  messageId: string;
  onProgress?: (progress: UploadProgress) => void;
  encryptionKey: CryptoKey; // Client-side E2EE key
}

export async function uploadMedia(options: MediaUploadOptions): Promise<string> {
  const { file, workspaceId, channelId, messageId, onProgress, encryptionKey } = options;

  // 1. Encrypt file client-side (E2EE)
  const encryptedBlob = await encryptFile(file, encryptionKey);

  // 2. Request pre-signed URL from media service
  const presignedResponse = await fetch('/api/media/upload-url', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      workspace_id: workspaceId,
      channel_id: channelId,
      message_id: messageId,
      media_type: getMediaType(file.type),
      filename: file.name,
      content_type: 'application/octet-stream', // Encrypted blob
      file_size: encryptedBlob.size,
    }),
  });

  const { upload_url, object_key, headers } = await presignedResponse.json();

  // 3. Upload directly to S3 using pre-signed URL
  await uploadToS3(upload_url, encryptedBlob, headers, onProgress);

  // 4. Return object key for message attachment
  return object_key;
}

async function uploadToS3(
  url: string,
  blob: Blob,
  headers: Record<string, string>,
  onProgress?: (progress: UploadProgress) => void
): Promise<void> {
  return new Promise((resolve, reject) => {
    const xhr = new XMLHttpRequest();

    xhr.upload.addEventListener('progress', (event) => {
      if (event.lengthComputable && onProgress) {
        onProgress({
          loaded: event.loaded,
          total: event.total,
          percentage: Math.round((event.loaded / event.total) * 100),
        });
      }
    });

    xhr.addEventListener('load', () => {
      if (xhr.status >= 200 && xhr.status < 300) {
        resolve();
      } else {
        reject(new Error(`Upload failed: ${xhr.status}`));
      }
    });

    xhr.addEventListener('error', () => reject(new Error('Upload failed')));

    xhr.open('PUT', url);
    Object.entries(headers).forEach(([key, value]) => {
      xhr.setRequestHeader(key, value);
    });
    xhr.send(blob);
  });
}

async function encryptFile(file: File, key: CryptoKey): Promise<Blob> {
  const iv = crypto.getRandomValues(new Uint8Array(12));
  const fileBuffer = await file.arrayBuffer();

  const encryptedBuffer = await crypto.subtle.encrypt(
    { name: 'AES-GCM', iv },
    key,
    fileBuffer
  );

  // Prepend IV to encrypted data
  const combined = new Uint8Array(iv.length + encryptedBuffer.byteLength);
  combined.set(iv);
  combined.set(new Uint8Array(encryptedBuffer), iv.length);

  return new Blob([combined], { type: 'application/octet-stream' });
}
```

---

## Event Notifications

### S3 Event Configuration

```hcl
# terraform/modules/s3/events.tf

resource "aws_s3_bucket_notification" "media_events" {
  bucket = aws_s3_bucket.media.id

  # Trigger Lambda for thumbnail generation
  lambda_function {
    lambda_function_arn = aws_lambda_function.thumbnail_generator.arn
    events              = ["s3:ObjectCreated:*"]
    filter_prefix       = "photos/"
  }

  lambda_function {
    lambda_function_arn = aws_lambda_function.video_processor.arn
    events              = ["s3:ObjectCreated:*"]
    filter_prefix       = "videos/"
  }

  # Send to SQS for async processing
  queue {
    queue_arn     = aws_sqs_queue.media_processing.arn
    events        = ["s3:ObjectCreated:*"]
    filter_suffix = ".enc"
  }

  # Notify on deletions for audit
  topic {
    topic_arn = aws_sns_topic.media_audit.arn
    events    = ["s3:ObjectRemoved:*"]
  }
}
```

### Thumbnail Generator Lambda

```python
# lambda/thumbnail-generator/handler.py

import boto3
import os
from PIL import Image
from io import BytesIO
import logging

logger = logging.getLogger()
logger.setLevel(logging.INFO)

s3 = boto3.client('s3')

THUMBNAIL_SIZES = {
    'small': (150, 150),
    'medium': (300, 300),
    'large': (600, 600),
}

THUMBNAILS_BUCKET = os.environ['THUMBNAILS_BUCKET']

def handler(event, context):
    for record in event['Records']:
        bucket = record['s3']['bucket']['name']
        key = record['s3']['object']['key']

        logger.info(f"Processing: s3://{bucket}/{key}")

        try:
            # Download original image
            response = s3.get_object(Bucket=bucket, Key=key)
            image_data = response['Body'].read()

            # Note: In production, you'd decrypt the E2EE data first
            # This example assumes server-side processing of non-E2EE thumbnails

            image = Image.open(BytesIO(image_data))

            # Generate thumbnails
            for size_name, dimensions in THUMBNAIL_SIZES.items():
                thumbnail = create_thumbnail(image, dimensions)

                # Upload thumbnail
                thumb_key = key.replace('photos/', f'thumbnails/{size_name}/')
                thumb_key = thumb_key.rsplit('.', 1)[0] + '.webp'

                buffer = BytesIO()
                thumbnail.save(buffer, format='WEBP', quality=85)
                buffer.seek(0)

                s3.put_object(
                    Bucket=THUMBNAILS_BUCKET,
                    Key=thumb_key,
                    Body=buffer,
                    ContentType='image/webp',
                    CacheControl='max-age=31536000',
                )

                logger.info(f"Created thumbnail: {thumb_key}")

        except Exception as e:
            logger.error(f"Error processing {key}: {str(e)}")
            raise

def create_thumbnail(image, size):
    """Create thumbnail maintaining aspect ratio"""
    image.thumbnail(size, Image.Resampling.LANCZOS)

    # Convert to RGB if necessary (for WEBP)
    if image.mode in ('RGBA', 'P'):
        background = Image.new('RGB', image.size, (255, 255, 255))
        background.paste(image, mask=image.split()[-1] if image.mode == 'RGBA' else None)
        return background

    return image.convert('RGB')
```

---

## IAM Policies

### Media Service Role

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "S3MediaAccess",
      "Effect": "Allow",
      "Action": [
        "s3:GetObject",
        "s3:PutObject",
        "s3:DeleteObject",
        "s3:GetObjectAttributes"
      ],
      "Resource": [
        "arn:aws:s3:::quikapp-media-*/*"
      ]
    },
    {
      "Sid": "S3ListBucket",
      "Effect": "Allow",
      "Action": [
        "s3:ListBucket"
      ],
      "Resource": [
        "arn:aws:s3:::quikapp-media-*"
      ]
    },
    {
      "Sid": "KMSDecrypt",
      "Effect": "Allow",
      "Action": [
        "kms:Decrypt",
        "kms:GenerateDataKey"
      ],
      "Resource": [
        "arn:aws:kms:*:*:key/media-*"
      ]
    }
  ]
}
```

---

## Monitoring & Metrics

### CloudWatch Metrics

```yaml
# cloudwatch/s3-alarms.yaml

Resources:
  S3StorageAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmName: QuikApp-S3-Storage-High
      MetricName: BucketSizeBytes
      Namespace: AWS/S3
      Statistic: Average
      Period: 86400
      EvaluationPeriods: 1
      Threshold: 1099511627776  # 1 TB
      ComparisonOperator: GreaterThanThreshold
      Dimensions:
        - Name: BucketName
          Value: quikapp-media-prod
        - Name: StorageType
          Value: StandardStorage

  S3RequestsAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmName: QuikApp-S3-Requests-High
      MetricName: AllRequests
      Namespace: AWS/S3
      Statistic: Sum
      Period: 300
      EvaluationPeriods: 3
      Threshold: 100000
      ComparisonOperator: GreaterThanThreshold
      Dimensions:
        - Name: BucketName
          Value: quikapp-media-prod

  S34xxErrorsAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmName: QuikApp-S3-4xx-Errors
      MetricName: 4xxErrors
      Namespace: AWS/S3
      Statistic: Sum
      Period: 300
      EvaluationPeriods: 2
      Threshold: 100
      ComparisonOperator: GreaterThanThreshold
```

---

## Terraform Modules

The complete Terraform configuration for S3 infrastructure is available in the `terraform/` directory:

```
terraform/
├── modules/
│   ├── s3/                    # S3 bucket module
│   │   ├── main.tf            # Bucket resources
│   │   ├── lifecycle.tf       # Lifecycle rules
│   │   ├── replication.tf     # Cross-region replication
│   │   ├── notifications.tf   # Event notifications
│   │   ├── variables.tf       # Input variables
│   │   └── outputs.tf         # Output values
│   ├── kms/                   # KMS encryption module
│   │   ├── main.tf            # KMS keys
│   │   ├── variables.tf       # Input variables
│   │   └── outputs.tf         # Output values
│   └── iam/                   # IAM policies module
│       ├── main.tf            # IAM roles and policies
│       ├── variables.tf       # Input variables
│       └── outputs.tf         # Output values
└── environments/
    ├── dev/                   # Development environment
    │   ├── main.tf            # Module composition
    │   ├── variables.tf       # Environment variables
    │   ├── outputs.tf         # Environment outputs
    │   └── terraform.tfvars   # Environment values
    └── prod/                  # Production environment
        ├── main.tf            # Module composition
        ├── variables.tf       # Environment variables
        ├── outputs.tf         # Environment outputs
        └── terraform.tfvars   # Environment values
```

### Quick Start

```bash
# Initialize Terraform
cd terraform/environments/dev
terraform init

# Plan changes
terraform plan

# Apply configuration
terraform apply
```

### Module Usage

```hcl
# Example: Using the S3 module
module "s3" {
  source = "../../modules/s3"

  environment          = "prod"
  kms_key_arn         = module.kms.s3_media_key_arn
  cors_allowed_origins = ["https://app.quikapp.com"]

  lifecycle_rules = {
    photos = {
      transition_to_ia_days      = 30
      transition_to_glacier_days = 90
      expiration_days            = 365
    }
    videos = {
      transition_to_ia_days      = 7
      transition_to_glacier_days = 30
      expiration_days            = 180
    }
    voice = {
      transition_to_ia_days = 7
      expiration_days       = 30
    }
    files = {
      transition_to_ia_days      = 30
      transition_to_glacier_days = 90
      expiration_days            = null
    }
  }

  enable_replication                  = true
  replication_destination_bucket_arn  = aws_s3_bucket.replica.arn

  tags = {
    Environment = "prod"
    Project     = "QuikApp"
  }
}
```

---

## Related Documentation

- [AWS Infrastructure](./aws.md) - Overall AWS architecture
- [CloudFront CDN](./cloudfront.md) - Content delivery configuration
- [Media Encryption](./media-encryption.md) - E2EE implementation details
- [Media Service](../microservices/go/media-service.md) - Go media microservice
