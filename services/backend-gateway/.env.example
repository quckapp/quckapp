# Application
NODE_ENV=development
PORT=3000
API_PREFIX=api/v1
# BASE_URL is used for file uploads - should match your backend URL
# Development: http://localhost:PORT (e.g., http://localhost:3000)
# Production: Your deployed backend URL (e.g., https://your-app.railway.app)
BASE_URL=http://localhost:3000

# Database - Separate URIs for Development and Production
# Development MongoDB (Local or Development Server)
MONGODB_URI_DEV=mongodb://localhost:27017/quickchat-dev

# Production MongoDB (Cloud MongoDB Atlas, Railway, etc.)
MONGODB_URI_PROD=mongodb://username:password@host:port/database?authSource=admin

# Legacy fallback (optional - if not using separate URIs)
MONGODB_URI=mongodb://localhost:27017/quickchat-dev

# JWT
JWT_SECRET=your-super-secret-jwt-key-change-this-in-production
JWT_EXPIRES_IN=7d
JWT_REFRESH_SECRET=your-super-secret-refresh-key-change-this-in-production
JWT_REFRESH_EXPIRES_IN=30d

# Encryption
ENCRYPTION_KEY=your-32-character-encryption-key-here-change-in-production

# CORS
CORS_ORIGIN=http://localhost:19006,http://localhost:8081

# CSRF Protection
# Cookie and header names for CSRF tokens
CSRF_COOKIE_NAME=XSRF-TOKEN
CSRF_HEADER_NAME=X-XSRF-TOKEN
# Token expiry in seconds (default: 1 hour)
CSRF_TOKEN_EXPIRY=3600
# Secret for CSRF token generation (falls back to JWT_SECRET if not set)
CSRF_SECRET=
# SameSite cookie attribute: strict, lax, or none
CSRF_SAME_SITE=lax

# File Upload
MAX_FILE_SIZE=10485760
UPLOAD_DIRECTORY=./uploads

# ========================================
# AWS S3 Configuration
# ========================================
# For cloud file storage (production recommended)
# Can also use S3-compatible services like MinIO, DigitalOcean Spaces, etc.

# AWS Credentials (optional if using IAM roles)
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
AWS_REGION=us-east-1

# S3 Bucket Configuration
AWS_S3_BUCKET=quckchat-uploads
# Custom endpoint for S3-compatible services (MinIO, LocalStack, etc.)
# AWS_S3_ENDPOINT=http://localhost:9000

# Storage mode: 'local' or 's3'
STORAGE_MODE=local

# Firebase (for push notifications)
# Get these from Firebase Console → Project Settings → Service Accounts → Generate New Private Key
# Development Firebase Service Account
FIREBASE_PROJECT_ID_DEV=your-firebase-project-id
FIREBASE_PRIVATE_KEY_DEV="-----BEGIN PRIVATE KEY-----\nyour-dev-private-key-content-here\n-----END PRIVATE KEY-----\n"
FIREBASE_CLIENT_EMAIL_DEV=firebase-adminsdk-dev@your-project-id.iam.gserviceaccount.com

# Production Firebase Service Account
FIREBASE_PROJECT_ID_PROD=your-firebase-project-id
FIREBASE_PRIVATE_KEY_PROD="-----BEGIN PRIVATE KEY-----\nyour-prod-private-key-content-here\n-----END PRIVATE KEY-----\n"
FIREBASE_CLIENT_EMAIL_PROD=firebase-adminsdk-prod@your-project-id.iam.gserviceaccount.com

# WebRTC TURN/STUN servers
TURN_SERVER_URL=turn:your-turn-server.com:3478
TURN_USERNAME=username
TURN_CREDENTIAL=credential
STUN_SERVER_URL=stun:stun.l.google.com:19302

# Rate limiting
THROTTLE_TTL=60
THROTTLE_LIMIT=100

# Redis Configuration (for caching and job queues)
# Install Redis locally or use a cloud service like Redis Cloud, Upstash, etc.
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=
REDIS_DB=0
# Separate Redis databases for different purposes (optional)
REDIS_CACHE_DB=0
REDIS_QUEUE_DB=1
# Enable Redis in development (default: false, uses in-memory cache)
USE_REDIS_IN_DEV=false
# Cache settings
CACHE_TTL=300
CACHE_MAX_ITEMS=1000

# OpenAI API (for AI-powered search)
OPENAI_API_KEY=your-openai-api-key-here

# ========================================
# Twilio SMS Configuration
# ========================================
# For OTP verification via SMS
# Sign up at https://www.twilio.com and get your credentials from the Console Dashboard

# Account SID (starts with AC)
TWILIO_ACCOUNT_SID=ACxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
# Auth Token (keep this secret!)
TWILIO_AUTH_TOKEN=your_auth_token_here

# Twilio Verify Service SID (starts with VA) - RECOMMENDED
# Create a Verify service in Twilio Console: https://console.twilio.com/us1/develop/verify/services
# This uses Twilio's managed OTP service with automatic code generation and validation
TWILIO_VERIFY_SERVICE_SID=VAxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Your Twilio phone number (format: +1234567890) - Only needed for basic SMS mode
# If TWILIO_VERIFY_SERVICE_SID is set, this is optional
TWILIO_PHONE_NUMBER=+1234567890

# SMTP Configuration (for email notifications)
# Common providers:
# - Gmail: smtp.gmail.com, port 587 (use App Password, not regular password)
# - SendGrid: smtp.sendgrid.net, port 587
# - Mailgun: smtp.mailgun.org, port 587
# - Amazon SES: email-smtp.{region}.amazonaws.com, port 587
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USER=your-email@gmail.com
SMTP_PASS=your-app-password
SMTP_FROM=QuickChat <noreply@quickchat.com>

# Monitoring and Observability

# Sentry Error Tracking (https://sentry.io)
# Create a project in Sentry and get the DSN from Project Settings → Client Keys
SENTRY_DSN=
# Enable Sentry in development (default: false)
SENTRY_ENABLE_DEV=false
APP_VERSION=1.0.0

# OpenTelemetry Tracing
# Use Jaeger locally (http://localhost:4318) or a cloud provider
OTEL_EXPORTER_OTLP_ENDPOINT=
OTEL_SERVICE_NAME=quickchat-backend
# Optional: Additional headers for cloud providers (JSON format)
# OTEL_EXPORTER_OTLP_HEADERS={"Authorization":"Bearer your-token"}

# Prometheus Metrics
# Metrics are exposed at /metrics endpoint by default
# Use the monitoring/docker-compose.monitoring.yml to run Prometheus + Grafana

# ========================================
# Message Brokers Configuration
# ========================================

# Apache Kafka Configuration
# For event streaming and high-throughput messaging between microservices
# Install Kafka locally or use Confluent Cloud, Amazon MSK, etc.
KAFKA_BROKERS=localhost:9092
KAFKA_CLIENT_ID=quckchat-backend
KAFKA_SSL=false
# Optional: SASL authentication for cloud Kafka
KAFKA_SASL_MECHANISM=plain
KAFKA_SASL_USERNAME=
KAFKA_SASL_PASSWORD=

# RabbitMQ Configuration
# For reliable message queuing with complex routing patterns
# Install RabbitMQ locally or use CloudAMQP, Amazon MQ, etc.
RABBITMQ_HOST=localhost
RABBITMQ_PORT=5672
RABBITMQ_USERNAME=guest
RABBITMQ_PASSWORD=guest
RABBITMQ_VHOST=/
# Optional: Use URL instead of individual settings
# RABBITMQ_URL=amqp://guest:guest@localhost:5672/

# ========================================
# HashiCorp Consul Configuration
# ========================================
# For service discovery and configuration management
# Install Consul locally or use HCP Consul (HashiCorp Cloud Platform)

# Consul agent address
CONSUL_HOST=localhost
CONSUL_PORT=8500
CONSUL_SECURE=false

# ACL token for authentication (if ACLs enabled)
CONSUL_TOKEN=

# Datacenter name
CONSUL_DATACENTER=dc1

# Service registration settings
CONSUL_SERVICE_NAME=quckchat-backend
CONSUL_SERVICE_PORT=3000

# ========================================
# HashiCorp Vault Configuration
# ========================================
# For secure secrets management in production
# Install Vault locally or use HCP Vault (HashiCorp Cloud Platform)

# Vault server address
VAULT_ADDR=http://127.0.0.1:8200

# Authentication - Choose one method:
# Option 1: Token authentication (simplest, for development)
VAULT_TOKEN=your-vault-token

# Option 2: AppRole authentication (recommended for production)
VAULT_ROLE_ID=
VAULT_SECRET_ID=

# Option 3: Kubernetes authentication (for K8s deployments)
VAULT_K8S_ROLE=

# Optional: Vault namespace (enterprise feature)
VAULT_NAMESPACE=

# ========================================
# APM (Application Performance Monitoring)
# ========================================

# Datadog APM Configuration
# Sign up at https://www.datadoghq.com and get your API key
DD_TRACE_ENABLED=false
DD_SERVICE=quckchat-backend
DD_ENV=development
DD_VERSION=1.0.0
DD_AGENT_HOST=localhost
DD_TRACE_AGENT_PORT=8126
DD_TRACE_SAMPLE_RATE=1
DD_RUNTIME_METRICS_ENABLED=true
DD_LOGS_INJECTION=true
DD_PROFILING_ENABLED=false

# New Relic APM Configuration
# Sign up at https://newrelic.com and get your license key
NEW_RELIC_ENABLED=false
NEW_RELIC_APP_NAME=QuckChat Backend
NEW_RELIC_LICENSE_KEY=your-new-relic-license-key
NEW_RELIC_LOG_LEVEL=info

# ========================================
# Code Quality (SonarQube)
# ========================================
# For local SonarQube server or SonarCloud

# SonarQube server URL (for local/self-hosted)
SONAR_HOST_URL=http://localhost:9000

# SonarQube authentication token
SONAR_TOKEN=your-sonar-token

# For SonarCloud (cloud-hosted)
# SONAR_ORGANIZATION=your-org

# ========================================
# Pino Logger Configuration
# ========================================
# Log level: fatal, error, warn, info, debug, trace
LOG_LEVEL=info
# Service name for log identification
SERVICE_NAME=quckchat-backend
# Log directory (for file transports)
LOG_DIRECTORY=logs
# Enable pretty printing in development
LOG_PRETTY_PRINT=true

# ========================================
# Rate Limiting Configuration
# ========================================
# Use Redis for distributed rate limiting (required for multi-instance deployments)
RATE_LIMIT_USE_REDIS=true
# Default rate limit window in milliseconds
RATE_LIMIT_WINDOW_MS=60000
# Default max requests per window
RATE_LIMIT_MAX_REQUESTS=100
# Enable sliding window algorithm (more accurate)
RATE_LIMIT_SLIDING_WINDOW=true

# ========================================
# AMQP Connection Manager Configuration
# ========================================
# Additional RabbitMQ hosts for cluster support (comma-separated)
# RABBITMQ_ADDITIONAL_HOSTS=rabbit2.example.com,rabbit3.example.com
# Connection heartbeat interval in seconds
RABBITMQ_HEARTBEAT=60
# Channel prefetch count
RABBITMQ_PREFETCH=10

# ========================================
# Internationalization (i18n) Configuration
# ========================================
# Default language for the application
DEFAULT_LANGUAGE=en
# Fallback language when translation is not found
FALLBACK_LANGUAGE=en
# Supported languages (comma-separated)
SUPPORTED_LANGUAGES=en,es,fr,de

# ========================================
# Database Migrations Configuration
# ========================================
# Run migrations automatically on application startup
MIGRATIONS_RUN_ON_STARTUP=false
# Directory containing migration scripts
MIGRATIONS_DIRECTORY=src/common/database/migrations/scripts

# ========================================
# PDF Generation Configuration
# ========================================
# Maximum PDF file size in bytes (default: 50MB)
PDF_MAX_SIZE=52428800
# Custom fonts directory (optional)
# PDF_FONTS_DIRECTORY=./fonts

# ========================================
# Archive/ZIP Configuration
# ========================================
# Maximum archive size in bytes (default: 100MB)
MAX_ARCHIVE_SIZE=104857600
# Temporary directory for archive generation
TEMP_ARCHIVE_DIRECTORY=./temp/archives
# Archive cleanup interval in hours
ARCHIVE_CLEANUP_INTERVAL=24

# ========================================
# CSV Import/Export Configuration
# ========================================
# Default delimiter for CSV parsing
CSV_DEFAULT_DELIMITER=,
# Maximum CSV file size for upload (default: 50MB)
CSV_MAX_FILE_SIZE=52428800
# Enable BOM for Excel compatibility
CSV_INCLUDE_BOM=true

# ========================================
# XML Configuration
# ========================================
# Pretty print XML output
XML_PRETTY_PRINT=true
# Default XML version
XML_VERSION=1.0
# Default XML encoding
XML_ENCODING=UTF-8

# ========================================
# Security - HTTP Parameter Pollution (HPP)
# ========================================
# Enable HPP protection
HPP_ENABLED=true
# Whitelist parameters that can have multiple values (comma-separated)
HPP_WHITELIST=ids,tags,categories,fields,include,exclude,sort,filters,participants,userIds,messageIds

# ========================================
# Mongoose Plugins Configuration
# ========================================
# Enable soft delete for all models
MONGOOSE_SOFT_DELETE=true
# Enable lean virtuals globally
MONGOOSE_LEAN_VIRTUALS=true
# Enable autopopulate globally
MONGOOSE_AUTOPOPULATE=true

# ========================================
# Spring Boot Auth Service Configuration
# ========================================
# Enable delegation to Spring Boot auth service
USE_SPRING_AUTH=false
# Enable delegation to Spring Boot for user profiles (requires USE_SPRING_AUTH or standalone)
# When enabled, user profiles, settings, and devices are managed in PostgreSQL via Spring Boot
USE_SPRING_PROFILES=false
# Spring Boot auth service URL
SPRING_AUTH_SERVICE_URL=http://localhost:8081/api/auth
# API key for service-to-service authentication
SPRING_AUTH_API_KEY=your-spring-auth-api-key
# Request timeout in milliseconds
SPRING_AUTH_TIMEOUT=10000
